[{"F:\\ReactJS\\ai_project_v1.1\\src\\index.js":"1","F:\\ReactJS\\ai_project_v1.1\\src\\reportWebVitals.js":"2","F:\\ReactJS\\ai_project_v1.1\\src\\App.js":"3"},{"size":500,"mtime":499162500000,"results":"4","hashOfConfig":"5"},{"size":362,"mtime":499162500000,"results":"6","hashOfConfig":"5"},{"size":5652,"mtime":1610715678645,"results":"7","hashOfConfig":"5"},{"filePath":"8","messages":"9","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"10"},"11b3bm4",{"filePath":"11","messages":"12","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"13"},{"filePath":"14","messages":"15","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"16","usedDeprecatedRules":"10"},"F:\\ReactJS\\ai_project_v1.1\\src\\index.js",[],["17","18"],"F:\\ReactJS\\ai_project_v1.1\\src\\reportWebVitals.js",[],["19","20"],"F:\\ReactJS\\ai_project_v1.1\\src\\App.js",["21"],"import \"./App.css\";\nimport \"@tensorflow/tfjs-backend-cpu\";\nimport { useEffect, useRef, useState } from \"react\";\n// Howler.js\nimport { Howl } from \"howler\";\n// Mobilenet & KNNClassifier\nimport * as mobilenet from \"@tensorflow-models/mobilenet\";\nimport * as knnClassifier from \"@tensorflow-models/knn-classifier\";\n// Source sound:\nimport sourceSound from \"./assets/warning_sound.mp3\";\n\n\nvar sound = new Howl({\n  src: [sourceSound],\n});\n\n// Labels for training:\nconst UNTOUCH_LABEL = \"untouch\";\nconst TOUCHED_LABEL = \"touched\";\nconst TRAINING_TIME = 50;\nconst MATCHING_RATE = 0.8;\n\nfunction App() {\n  const video = useRef();\n  const classifier = useRef();\n  const model = useRef();\n  const playSound = useRef(true);\n  const [touched, setTouched] = useState(false);\n  const init = async () => {\n    // CAMERA==================================\n    let loadCamera = document.getElementById(\"loading\");\n    console.log(\"Setting up the camera...\");\n    loadCamera.textContent = \"Setting up camera, please wait...\";\n    await setupCamera();\n\n    console.log(\"Set up camera successfully\");\n    // LIBRARIES===============================\n    console.log(\"Loading the libraries...\");\n    loadCamera.textContent = \"Loading necessary libraries, please wait...\"\n    // Load the ImageNet database:\n    model.current = await mobilenet.load();\n    // Create the classifier.\n    classifier.current = knnClassifier.create();\n    console.log(\"Load libraries successfully\");\n    loadCamera.textContent = \"Load libraries successfully\";\n  };\n\n  const setupCamera = () => {\n    return new Promise((resolve, reject) => {\n      navigator.getUserMedia =\n        navigator.getUserMedia ||\n        navigator.webkitGetUserMedia ||\n        navigator.mozGetUserMedia ||\n        navigator.msGetUserMedia;\n      if (navigator.getUserMedia) {\n        navigator.getUserMedia(\n          { video: true },\n          (stream) => {\n            video.current.srcObject = stream;\n            video.current.addEventListener(\"loadeddata\", resolve);\n          },\n          (error) => reject(error)\n        );\n      } else {\n        reject();\n      }\n    });\n  };\n  const train_process = async (label) => {\n    let process = document.getElementById(\"process\");\n    console.log(`[${label}]`);\n    for (let i = 0; i < TRAINING_TIME; ++i) {\n      console.log(`Training ${parseInt(((i + 1) / TRAINING_TIME) * 100)}%...`);\n      let percent = `${parseInt(((i + 1) / TRAINING_TIME) * 100)}%...`;\n      process.textContent = \"Traning for: \" + label + \" \" + percent;\n      await train(label);\n    }\n\n    if (label === \"untouch\") {\n      process.textContent = \"Hit the TOUCHED button.\";\n    } else if (label === \"touched\") {\n      process.textContent = \"Hit the TEST button.\";\n    } else {\n      process.textContent = \"\";\n    }\n  };\n\n  const train = (label) => {\n    return new Promise(async (resolve) => {\n      /* DOCs\n        model.infer(\n        img: tf.Tensor3D | ImageData | HTMLImageElement |\n        HTMLCanvasElement | HTMLVideoElement,\n        embedding = false\n        )\n\n\n        classifier.addExample(\n        example: tf.Tensor,\n        label: number|string\n        ): void;\n        * param1 - example: An example to add to the dataset, usually an activation from another model.\n        * param2 - label: The label (class name) of the example.\n\n\n      */\n\n      const embedding = model.current.infer(video.current, true);\n\n      classifier.current.addExample(embedding, label);\n      await sleep(100);\n      resolve();\n    });\n  };\n  const run = async () => {\n    const embedding = model.current.infer(video.current, true);\n    /*  Return an object where:\n      * label: the label (class name) with the most confidence.\n      * classIndex: the 0-based index of the class (for backwards compatibility).\n      * confidences: maps each label to their confidence score.\n      => {\n          label: string,\n          classIndex: number,\n          confidences: {\n            [classId: number]: number\n                }\n\n          }\n    */\n    const result = await classifier.current.predictClass(embedding);\n\n    if (\n      result.label === TOUCHED_LABEL &&\n      result.confidences[result.label] > MATCHING_RATE\n    ) {\n      console.log(\"Touched\");\n      if(playSound.current) {\n          sound.play();\n          playSound.current = false;\n      }\n      \n      setTouched(true);\n    } else {\n      console.log(\"Untouch\");\n      setTouched(false);\n    }\n\n    /* Test 5 lần/ 1 giây\n             => 1 lần -> 0.2 giây -> 200 mili giây \n          */\n    await sleep(200);\n    run();\n  };\n\n  const sleep = (milliSecond = 0) => {\n    return new Promise((resolve) => setTimeout(resolve, milliSecond));\n  };\n  useEffect(() => {\n    sound.on(\"end\", function () {\n      playSound.current = true;\n    });\n\n    init();\n    // Clean up\n    return () => {};\n  }, []);\n\n  return (\n    <div className={`app ${touched ? \"touched\" : \"\"}`}>\n      <div className = \"heading\">\n        <h1 className=\"title\">Warning Touch Your Face</h1>\n        <p className = \"description\">AI Project 2021</p>\n        <p id = \"loading\"></p>\n      </div>\n      <video ref={video} className=\"video\" autoPlay />\n      <div className=\"control\">\n        <button className=\"btn\" onClick={() => train_process(UNTOUCH_LABEL)}>\n          UNTOUCH\n        </button>\n        <button className=\"btn\" onClick={() => train_process(TOUCHED_LABEL)}>\n          TOUCHED\n        </button>\n        <button className=\"btn\" onClick={() => run()}>\n          TEST\n        </button>\n      </div>\n      <div className=\"info\">\n        <p id=\"process\">Do not touch your face and hit the UNTOUCH button.</p>\n      </div>\n    </div>\n  );\n}\n\nexport default App;\n",{"ruleId":"22","replacedBy":"23"},{"ruleId":"24","replacedBy":"25"},{"ruleId":"22","replacedBy":"26"},{"ruleId":"24","replacedBy":"27"},{"ruleId":"28","severity":1,"message":"29","line":166,"column":6,"nodeType":"30","endLine":166,"endColumn":8,"suggestions":"31"},"no-native-reassign",["32"],"no-negated-in-lhs",["33"],["32"],["33"],"react-hooks/exhaustive-deps","React Hook useEffect has a missing dependency: 'init'. Either include it or remove the dependency array.","ArrayExpression",["34"],"no-global-assign","no-unsafe-negation",{"desc":"35","fix":"36"},"Update the dependencies array to be: [init]",{"range":"37","text":"38"},[4802,4804],"[init]"]